{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install google-api-python-client youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load API key from configuration file\n",
    "with open('config.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "    API_KEY = config.get('YT_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An HTTP error 403 occurred: b'{\\n  \"error\": {\\n    \"code\": 403,\\n    \"message\": \"The request cannot be completed because you have exceeded your \\\\u003ca href=\\\\\"/youtube/v3/getting-started#quota\\\\\"\\\\u003equota\\\\u003c/a\\\\u003e.\",\\n    \"errors\": [\\n      {\\n        \"message\": \"The request cannot be completed because you have exceeded your \\\\u003ca href=\\\\\"/youtube/v3/getting-started#quota\\\\\"\\\\u003equota\\\\u003c/a\\\\u003e.\",\\n        \"domain\": \"youtube.quota\",\\n        \"reason\": \"quotaExceeded\"\\n      }\\n    ]\\n  }\\n}\\n'\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, TranscriptsDisabled\n",
    "from collections import deque\n",
    "import time\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, TranscriptsDisabled\n",
    "from xml.etree.ElementTree import ParseError\n",
    "\n",
    "# Initialize YouTube API client\n",
    "youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
    "\n",
    "# Keywords to filter videos\n",
    "keywords = [\n",
    "    \"Resume\",\n",
    "    \"Resume Advice\",\n",
    "    \"Resume Writing\",\n",
    "    \"Resume Tips\",\n",
    "    \"How to Write a Resume\",\n",
    "    \"Best Resume Practices\",\n",
    "    \"Resume Formatting\",\n",
    "    \"Resume Examples\",\n",
    "    \"Resume Templates\",\n",
    "    \"Professional Resume\",\n",
    "    \"Resume Design\",\n",
    "    \"Resume Optimization\",\n",
    "    \"Resume Building\",\n",
    "    \"Resume Help\",\n",
    "    \"Resume Guide\",\n",
    "    \"Resume Writing Tips\",\n",
    "    \"Crafting a Resume\",\n",
    "    \"Resume Content\",\n",
    "    \"Resume Strategy\",\n",
    "    \"Resume Review\",\n",
    "    \"Resume Critique\",\n",
    "    \"Resume Updates\",\n",
    "    \"Resume Editing\",\n",
    "    \"Resume and Cover Letter\",\n",
    "    \"Resume Writing Skills\",\n",
    "    \"Effective Resume\",\n",
    "    \"Resume for Job Applications\",\n",
    "    \"Tailoring Your Resume\",\n",
    "    \"Resume Keywords\",\n",
    "    \"Resume Structure\",\n",
    "    \"Resume Sections\",\n",
    "    \"Resume Personalization\",\n",
    "    \"Resume Objective\",\n",
    "    \"Resume Summary\",\n",
    "    \"Resume Experience\",\n",
    "    \"Resume Accomplishments\",\n",
    "    \"Resume Achievements\",\n",
    "    \"Resume for Career Change\",\n",
    "    \"Resume for Entry-Level Jobs\",\n",
    "    \"Resume for Experienced Prof\"\n",
    "]\n",
    "\n",
    "def search_videos_by_keywords(keywords, max_results=20):\n",
    "    try:\n",
    "        search_results = []\n",
    "        for keyword in keywords:\n",
    "            request = youtube.search().list(\n",
    "                part='snippet',\n",
    "                q=keyword,\n",
    "                type='video',\n",
    "                maxResults=max_results\n",
    "            )\n",
    "            response = request.execute()\n",
    "            search_results.extend(response['items'])\n",
    "        return search_results\n",
    "    except HttpError as e:\n",
    "        print(f\"An HTTP error {e.resp.status} occurred: {e.content}\")\n",
    "        return []\n",
    "\n",
    "def get_video_details(video_ids):\n",
    "    try:\n",
    "        video_details = []\n",
    "        for video_id in video_ids:\n",
    "            request = youtube.videos().list(\n",
    "                part='snippet',\n",
    "                id=video_id\n",
    "            )\n",
    "            response = request.execute()\n",
    "            video_details.extend(response['items'])\n",
    "        return video_details\n",
    "    except HttpError as e:\n",
    "        print(f\"An HTTP error {e.resp.status} occurred: {e.content}\")\n",
    "        return []\n",
    "\n",
    "def get_transcript(video_id, retries=3, delay=5):\n",
    "    attempt = 0\n",
    "    while attempt < retries:\n",
    "        try:\n",
    "            transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "            transcript_text = ' '.join([t['text'] for t in transcript])\n",
    "            print(f\"Transcript found for video ID: {video_id}\")\n",
    "            return transcript_text\n",
    "        except NoTranscriptFound:\n",
    "            print(f\"No transcript found for video ID: {video_id}\")\n",
    "            return None\n",
    "        except TranscriptsDisabled:\n",
    "            print(f\"Transcripts are disabled for video ID: {video_id}\")\n",
    "            return None\n",
    "        except ParseError as e:\n",
    "            print(f\"ParseError occurred for video ID: {video_id}. Error: {str(e)}\")\n",
    "            attempt += 1\n",
    "            time.sleep(delay)  # Wait before retrying\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred for video ID: {video_id}. Error: {str(e)}\")\n",
    "            return None\n",
    "    print(f\"Failed to retrieve transcript after {retries} attempts for video ID: {video_id}\")\n",
    "    return None\n",
    "\n",
    "def filter_videos(videos, keywords):\n",
    "    filtered_videos = []\n",
    "    for video in videos:\n",
    "        if any(keyword.lower() in video['snippet']['title'].lower() for keyword in keywords):\n",
    "            filtered_videos.append({\n",
    "                'title': video['snippet']['title'],\n",
    "                'videoId': video['id'],\n",
    "                'transcript': ''\n",
    "            })\n",
    "    return filtered_videos\n",
    "\n",
    "def crawl_videos(start_video_id, keywords, max_depth=2, max_videos=50):\n",
    "    crawled_videos = []\n",
    "    video_queue = deque([(start_video_id, 0)])\n",
    "    visited_videos = set()\n",
    "\n",
    "    while video_queue and len(crawled_videos) < max_videos:\n",
    "        current_video_id, depth = video_queue.popleft()\n",
    "        if depth > max_depth or current_video_id in visited_videos:\n",
    "            continue\n",
    "        \n",
    "        visited_videos.add(current_video_id)\n",
    "\n",
    "        # Get video details and related videos\n",
    "        search_results = search_videos_by_keywords(keywords)\n",
    "        video_ids = [item['id']['videoId'] for item in search_results if 'videoId' in item['id']]\n",
    "        video_details = get_video_details(video_ids)\n",
    "\n",
    "        filtered_videos = filter_videos(video_details, keywords)\n",
    "        \n",
    "        for video in filtered_videos:\n",
    "            if video['videoId'] not in visited_videos:\n",
    "                transcript = get_transcript(video['videoId'])\n",
    "                if transcript:\n",
    "                    video['transcript'] = transcript\n",
    "                crawled_videos.append(video)\n",
    "                video_queue.append((video['videoId'], depth + 1))\n",
    "                time.sleep(1)  # To avoid hitting rate limits\n",
    "    \n",
    "    return crawled_videos\n",
    "\n",
    "# Function to save transcripts to a file\n",
    "def save_transcripts_to_file(videos, filename='corpus_from_web_crawler.txt'):\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        for video in videos:\n",
    "            title = video['title']\n",
    "            video_id = video['videoId']\n",
    "            transcript = video.get('transcript', 'No transcript available')\n",
    "\n",
    "            # Write video title and ID\n",
    "            file.write(f\"Title: {title}\\n\")\n",
    "            file.write(f\"Video ID: {video_id}\\n\")\n",
    "            \n",
    "            # Write transcript\n",
    "            file.write(f\"Transcript:\\n{transcript}\\n\")\n",
    "            \n",
    "            # Add a separator between different video transcripts\n",
    "            file.write(\"\\n\" + \"-\"*80 + \"\\n\\n\")\n",
    "\n",
    "# Start Crawling\n",
    "start_video_id = 'Tt08KmFfIYQ'  # Replace with the actual starting video ID\n",
    "crawled_videos = crawl_videos(start_video_id, keywords)\n",
    "\n",
    "# Save transcripts to file\n",
    "save_transcripts_to_file(crawled_videos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
